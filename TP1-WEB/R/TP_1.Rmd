---
title: "TP 1"
author: "EL Hadrami N'DOYE et Ismaïl RAMDÉ"
date: "15/01/2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE, warning = FALSE)
```

```{r}
library(tinytex)
```


# Exercice 1

```{r}
# importation du fichier ScriptEtud.R
source("scriptsEtud.R")
```

$\underline{\textbf{Estimation d’une proportion dans le contexte d’une question délicate}}$

```{r}
n <- 500
P <- 1 / 10
theta <- 0.8
n.sim <- 1000
set.seed(2001)
piaw <- questDelicateMeth1(n,P,theta,n.sim)
```


$\textbf{Question 1 . Simulation 1000 fois de la methode 1}$

\textbf{a. Calcul de la moyenne et l'ecart type estimés}


On sait que la moyenne estimée correspond à l’espérance tant-disque l’écart-type estimé correspond à la  racine carré de la variance.
Ici X suit une loi Binomiale.

Donc $E(X) = a+ b*(n*P)$ et $var = b^2 * (n*P(1-P))$

```{r}
probaoui1 <- P * (2 * theta - 1) - theta + 1
# X est une loi Binomiale
X <- rbinom(n.sim,n,probaoui1)
a <- (theta - 1) / ((2 * theta) - 1)
b <- 1 / (n * ((2 * theta) - 1))

# Moyenne estimée
moyenneEst1 <- a + (b * n * probaoui1)
moyenneEst1
# Ecart type estimé
varX1 <- n * probaoui1 * (1 - probaoui1)
ecarttype1 <- sqrt(b^2 * varX1)
ecarttype1
```

$\textbf{b. Les valeurs theoriques correspondantes}$

```{r}
# moyenne
mean(piaw)
# écart-type
sd(piaw)
```

$\textbf{c. Comment se compare la variance de cette méthode avec celle,}\\$
$\textbf{ou l’on poserait directement la question dans le contexte où tous les répondants répondent honnêtement}$?

Dans le cas où tous les repondants repondent honêtement, la variance serait inférieur à celle de la méthode precedente.

$\textbf{d. Tracé d'un histogramme des valeurs observées de} \ \boldsymbol{\widehat{\pi}_{AW}}$


```{r}
hist(piaw,probability = TRUE,col = "blue")
```

$\textbf{e. Commentaires}$

Après les différents calculs, on remarque la moyenne estimée et la l’écart-type estimé sont respectivement égaux à la moyenne théorique et l’écart-type théorique. Aussi on trouve que les estimateurs sont sans biais. Pour finir à travers l’histogramme, on voit que la distribution suit une loi normale.
\newline 

$\textbf{2. Reprise du travail avec la méthode 2 en utilisant} \  \boldsymbol{\alpha = 0.217}$

```{r}
alpha <- 0.217
pia <- questDelicateMeth2(n, P, theta, alpha, n.sim)
```

$\textbf{a. Calcul de la moyenne et l'ecart type estimés}$

```{r}
probaoui2 <- (theta * P) + ((1 - theta) * alpha) 
a <- alpha * (theta - 1) / theta
b <- 1 / (n * theta)

# Moyenne estimée
moyenneEst2 <- a + (b * n * probaoui2)
moyenneEst2
# Ecart type estimé
varX2 <- n * probaoui2 * (1 - probaoui2)
ecarttype2 <- sqrt((1 / (n * theta)^2) * varX2)
ecarttype2
```

$\textbf{b. Les valeurs theoriques correspsecarreondantes}$

```{r}
# moyenne
mean(pia)
# écart-type
sd(pia)
```

$\textbf{c. Comment se compare la variance de cette méthode avec celle où,}\\$ \textbf{l’on poserait directement la question dans le contexte où tous les répondants répondent honnêtement}$?

Dans le cas où tous les repondants repondent honêtement, la variance serait inférieur à celle de la méthode precedente.

 $\textbf{d. Tracage d'un histogramme des valeurs observées} \ de \  \boldsymbol{\widehat{\pi}_{AW}}$


```{r}
hist(pia,probability = TRUE,col = "red")
```

$\textbf{3. Évaluons les différentes EQM}$

```{r}
# méthode (b)
EQM1 <- varX2 + (moyenneEst2 - theta)
EQM1
```

Calculons de $\widehat{\pi}_{AW}$
```{r}
prop <- c(0, 0.1, 0.2, 0.3)
prob <- 1 - prop
prob
set.seed(2001)
piaw1 <- rep(0,4)
piaw1
for (i in 1:4) {
  piaw1[i] <- questDelicateMeth1(n,prob[i],theta,n.sim)
}
piaw1

# calcul de la moyenne estimée et de le variance estimé 

# Moyenne estimée
moyenEst <- mean(piaw1)
moyenEst
# Ecart type estimé
var1 <- var(piaw1)
var1

EQM2 <- var1 + (moyenEst - theta)
EQM2
```

La méthode (a) a une EQM plus petite que celle de la méthode (b).
\newline
\newline 



$\textbf{Question 4 . Échantillonnage classique}$

$\textbf{a. Calcul de} \  \boldsymbol{\bar{y}_{u}} \  \textbf{et  S pour la population}$

```{r}
source("Script2.R")
ybarru <- sum(pop) / N
sigmacarre <- (1 / N) * sum((pop - ybarru)^2)
S <- sqrt((sigmacarre * N) / (N - 1))
```

### b. Generation d'une trame de données contenant toutes les echantillons possibles

```{r}
head(ech.all)
```


### c. Création de la nouvelle trame de données

```{r}
options(OutDe=",")
pop <- c (3 , 6 , 24 , 27 , 30 , 36 , 51 , 57)
N <- length ( pop )
n <- 3
(n.ech <- choose (N , n))
ech.all <- cbind ( choix <- t ( matrix ( combn (1: N , n ) ,n , n.ech ) ) ,
                   ( matrix (pop [ choix ] , n.ech , n ) ) )
head (ech.all)
donneepop <- ech.all[,4:6]
ybar <- apply(donneepop,1,mean)
s <- apply(donneepop,1,sd)
sigmachapeau.ybar <- (1 - (n / N)) * (s^2 / n)
b.inf <- ybar - (1.96 * sqrt(sigmachapeau.ybar))
b.sup <- ybar + (1.96 * sqrt(sigmachapeau.ybar))
size <- 56
incl <- rep(0,size)
for (i in 1:size){
  if(ybarru <= b.sup[i] && ybar >= b.inf[i]){
    incl[i] <- 1
  }
  else{
    incl[i] <- 0
  }
}
tram.donnee <- cbind(ybar,s,b.inf,b.sup,incl)
head(tram.donnee,5)

```

### d. Verifions numeriquement que $\boldsymbol{\mu_{\bar{y}}=\bar{y_{u}}}$ et que $\boldsymbol{\sigma_{\bar{y}}$=($\sqrt{1-f}$)$\frac{S}{n}}$

```{r}
# moyenne de chaque population a 3 echantillons
muybarr <- mean(tram.donnee[,1]) 
muybarr
ybarru
f <- n / N
head(sqrt(1 - f) * (S / sqrt(n)),5)
sygmaybarr <- sqrt((1 - (n / N)) * (S^2 / n))
sygmaybarr
```

### e. s est-il un estimateur sans biais de S ?

  
```{r}
esp <- cumsum(tram.donnee[,2]) / (1:size)
plot(esp,xlim = c(min(esp),max(esp)),type = "l",col="blue",main = "esperance de S / s")
abline(h = S,col="red")
legend(x = 18,y = 14,legend=c("esperance de s","Valeur de S"),fill = c("blue","red"),
       col=c("blue,red"))
```

D’après la figure on observe que l’esperance  de s ne converge pas vers la valeur de S.
Donc s n'est pas un estimateur sans biais  de S.


$\textbf{f. Déterminer la probabilité de commettre dans l’estimation de la moyenne une erreur}$

- plus de deux unités

On compte toutes les indices du vecteurs ybar dont leurs valeurs sont superieur a $\bar{y_{u}}+5$ puis on divise par le nombre d'element du vecteur ybar pour avoir la probabilité.


```{r}
length(which(ybar > ybarru + 2 )) / size
```

- plus de cinq unités

On compte toutes les indices du vecteurs ybar  dont leurs valeurs sont superieur a $\bar{y_{u}}+5$ puis on divise par le nombre d'element du vecteur ybar pour avoir la probabilité.


```{r}
length(which(ybar > ybarru + 5 )) / size
```

- plus de $25\%$

On compte toutes les indices du vecteurs ybar  dont leurs valeurs sont superieur a $\bar{y_{u}}+0.25$ puis on divise par le nombre d'element du vecteur ybar pour avoir la probabilité.

```{r}
length(which(ybar > ybarru + 0.25 )) / size
```


**g. Calcul de la probabilité de se tromper de plus de $20\%$ dans l’estimation de l’écart type S de la population**.

```{r}
length(which(s > S + 0.20 )) / size
```

**h.Le niveau de confiance de l’intervalle de confiance donné par la formule**

$\bar{y}-2\widehat{\sigma}_{\bar{y}}\leq \bar{y}_{u}\leq \bar{y}+2\widehat{\sigma}_{\bar{y}}$

On compte le nombre d'element de $\bar{y}-2\widehat{\sigma}_{\bar{y}}$ et  $\bar{y}+2\widehat{\sigma}_{\bar{y}}$ dont $\bar{y}-2\widehat{\sigma}_{\bar{y}} \leq \bar{y}_{u} \leq \bar{y}+2\widehat{\sigma}_{\bar{y}}$ 

```{r}
born.inf <- ybar - (2 * sqrt(sigmachapeau.ybar))
born.sup <- ybar + (2 * sqrt(sigmachapeau.ybar))
length(which(ybarru >= born.inf & ybarru <= born.sup)) / size
```

Donc le niveau de confiance de cette intervall est de $89.28\%$

**i.Le niveau de confiance de l’intervalle de confiance donné par la formule**

$\bar{y}-3\widehat{\sigma}_{\bar{y}}\leq \bar{y}_{u}\leq \bar{y}+3\widehat{\sigma}_{\bar{y}}$

```{r}
born.inf <- ybar - (3 * sqrt(sigmachapeau.ybar))
born.sup <- ybar + (3 * sqrt(sigmachapeau.ybar))
length(which(ybarru >= born.inf & ybarru <= born.sup)) / size
```
Donc le niveau de confiance de cette intervall est de $92.86\%$

**j.Le niveau de confiance de l’intervalle de confiance donné par la formule**

$\bar{y}-2\sigma_{\bar{y}}\leq \bar{y}_{u}\leq \bar{y}+2\sigma_{\bar{y}}$

```{r}
born.inf <- ybar - (2 * sygmaybarr)
born.sup <- ybar + (2 * sygmaybarr)
length(which(ybarru >= born.inf & ybarru <= born.sup)) / size
```

Donc le niveau de confiance de cette intervall est de $92.86\%$

$\textbf{5.a: Dans quelle mesure nos simulations confirment-elles que} \ \boldsymbol{\bar{y}},\\ \textbf{est un estimateur sans biais de} \ \boldsymbol{\bar{y}_{u}}$

```{r}
# Realisation d'un script creant un echantillon de taille 5 1000 fois
y <- c (36 , 36.5 , 37 , 37.5 , 38 , 38.5 , 39 , 39.5 , 
        40 , 40.5,41 ,41.5 , 42 , 42.5 , 43 , 
        43.5 , 44 , 44.5 , 45 , 45.5 , 46 ,46.5)
e <- c (0.02 , 0.03 , 0.04 , 0.06 , 0.10 , 0.12 , 0.13 , 0.10 , 0.07 , 0.05 , 
        0.05 , 0.04 , 0.04, 
        0.03 , 0.03 , 0.02 , 0.02 , 0.01 , 0.01 , 0.01 , 0.01 ,  0.01)
# Taille de l'echantillon
NE <- 1000
ne <- 5
echt <- matrix(rep(NA,NE),nrow = NE,ncol = ne)
set.seed(2001)
for (i in 1:NE){
  echt[i,] <- sample (y ,ne , replace = TRUE , prob = e )
}
ybarr <- apply(echt, 1,mean)
mean(ybarr)
ybarru <- mean(y)
ybarru
```

Apres avoir simuler 1000 fois des echantillons de taille 5 on constate que $\bar{y}$ est un estimateur sans biais de $\bar{y}_{u}$ a partir de la mesure 40.

$\textbf{5.b Calcule de  la variance des} \ \boldsymbol{\bar{y}} \ \textbf{Théoriquement,
que devrait être cette variance}?,\\ \textbf{Énoncons le théorème qui justifie notre reponse}$

```{r}
varybarr <- var(ybarr)
varybarr
(1 / (NE - 1)) * sum((ybarr - mean(ybarr))^2)
```


$\textbf{5.c La variable}$ $\boldsymbol{\bar{y}}$ \ $\textbf{suit-elle une loi normale}$:


```{r}
hist(ybarr,probability = TRUE,xlim = c(min(ybarr),max(ybarr)),ylim = c(0,0.4),col="green",
     main="histogramme /densité")
lines(density(ybarr),col="red")
legend(x=41,y=0.4,c("histogramme","densité"),fill = c("green","red"),col =c("green","red"))
```

$\textbf{Test de normalité}$


```{r}
shapiro.test(ybarr)
```


Soient les deux hypothèses suivantes:

$H_{0}:$la variable $\bar{y}$ est une loi normale $\\$
$H_{a}:$la variable $\bar{y}$ n'est pas une loi normale $\\$

-Décision

le p-value est inférieur a la valeur de alpha fixée ($\alpha=0.05$), donc on rejette $H_{0}$ et on accepte $H_{a}.\\$  Donc $\bar{y}$ n'est pas une loi normale.



$\textbf{Question d:}$


```{r}
# calcul de sigma y bar
sycarr <- (1 / length(y)) * sum((y - ybarru)^2)
sigmaybar <- sqrt(sycarr / ne)
length(which(ybarr > 1.96 * sd(ybarr))) / NE
```

$\text{e.La probabalité de recouvrement de l'intervalle de confiance}$


```{r}
se <- apply(echt,1,sd)
a <- ybarr - (1.96 * (se / sqrt(ne)))
b <- ybarr + (1.96 * (se / sqrt(ne)))
length(which(ybarru <= b & ybarru >=a)) / NE
```
$\text{Donc la probabilité que l'intervall de confiance qui recouvre la vraie moyenne est de}\ 54.6 \%.$

$\textbf{Question f : Est-ce que vos simulations semblent indiquer que l’estimateur}$ $\boldsymbol{s^2}$ $\textbf{est sans biais}$ de $\boldsymbol{S^2}$

```{r}
secarr <- se^2
sizey <- length(y)
# calcul de S^2
S.carre <- (1 / (sizey - 1)) * sum((y - mean(y))^2)
espsecarre <- cumsum(secarr / (1:length(secarr)))
plot(espsecarre,xlim = c(min(espsecarre),max(espsecarre)),type = "l",
     col="blue",main = "espsecarreerance de S / s")
abline(h = S.carre,col="red")
legend(x = 18,y = 40,legend=c("espsecarreerence de s^2","Valeur de S^2"),
       fill = c("blue","red"),col=c("blue,red"))
```

D’après la figure on observe que l’esperance  de $s^2$ ne converge pas vers la valeur de $S^2$.
Donc  $s^2$ n'est pas un estimateur sans biais  de  $S^2$.


\textbf{Question g:La théorie statistique indique que dans certaines conditions l’intervalle de confiance
calculé par la formule}

$$\frac{(n-1)*s^2}{\chi^2_{\alpha/2;n-1}}<S^2<\frac{(n-1)*s^2}{\chi^2_{1-\alpha/2;n-1}}$$
est un intervalle de confiance à $95\%$. Estimons le niveau réel de cet intervalle de
confiance.

```{r}
alhaseuil <- 0.05
bsup <- ((ne - 1) * secarr) / qchisq(alhaseuil/2,ne - 1)
binf<- ((ne - 1) * secarr) / qchisq(1-(alhaseuil / 2),ne - 1)
length(which(S.carre < bsup & S.carre > binf)) / NE
```
Le niveau reel de cet intervall de confiance est de $86.6\%$.
