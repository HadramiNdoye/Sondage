---
title: "TP_2"
author: "EL_Hadrami_N'DOYE_Florence"
date: "22/01/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
source("TP2Etudiant.R")
```

## EXERCICE

$1.\ $ Soit $N = 6$ et $n = 3$. Afin d’étudier les distributions des estimateurs, nous supposons
connues les valeurs pour toute la population :

$$y_{1} = 98 \ \ y_{3} = 154 \ \  y_{5} = 190$$
$$y_{2} = 102 \ \ y_{4} = 133 \ \ y_{6} = 175$$

**(a) : Déterminons les probabilités d’inclusion du premier et du second ordre pour ces deux plans de sondages.**

$\underline{\textbf{Plan1}}$

- Probabilité d'inclusion du premier ordre

```{r}
n <- 3
N <- 6
x <- plan1[,1:3]
k <- c(1:6)
# nombre d'echantillons
sizeech <- nrow(plan1)
appartenancepik <- matrix(rep(NA,sizeech * N),nrow = N ,ncol=sizeech)
rownames(appartenancepik) <- paste("k=",k)
colnames(appartenancepik) <- paste("ech",1:sizeech)
pik <-  matrix(rep(NA,sizeech * N),nrow = N ,ncol=sizeech)
rownames(pik) <- paste("k=",k)
colnames(pik) <- paste("ech",1:sizeech)
  for (i in 1:sizeech){
    for(j in 1:N){
        appartenancepik[j,i] <- un_dedans(x[i,],k[j])
        appartenancepik[appartenancepik==TRUE] <- 1
        appartenancepik[appartenancepik==FALSE] <- 0
        pik[j,i] <- round(appartenancepik[j,i] / n,2)
    }
  
  }
  head(appartenancepik,6)
  head(pik,6)
```

- Probabilité d'inclusion du second ordre

```{r}
sizek <- choose(N,2)
# couple i,jech
coupleij <- t(combn(k,2))
appartenancepikl <- matrix(rep(NA,sizek * sizeech),nrow = sizek ,ncol=sizeech)
rownames(appartenancepikl) <- paste(coupleij[,1],coupleij[,2],sep = ",")
colnames(appartenancepikl) <- paste("ech",1:sizeech)
pikl <-  matrix(rep(NA,sizek * sizeech),nrow = sizek ,ncol=sizeech)
rownames(pikl) <- paste(coupleij[,1],coupleij[,2],sep = ",")
colnames(pikl) <- paste("ech",1:sizeech)
  for (i in 1:sizek){
    for(j in 1:sizeech){
        appartenancepikl[i,j] <- deux_dedans(x[j,],coupleij[i,1],coupleij[i,2])
        appartenancepikl[appartenancepikl==TRUE] <- 1
        appartenancepikl[appartenancepikl==FALSE] <- 0
        pikl[i,j] <- round(appartenancepikl[i,j] / n,2)
    }
   
    
  }
 head(appartenancepikl,6)
 head(pikl,6)
```

$\underline{\textbf{Plan2}}$


- Probabilité d'inclusion du premier ordre

```{r}
ind <- plan2[,1:3]
sizeind <- nrow(ind)
appartenancepikp2 <- matrix(rep(NA,sizeind * N),nrow = N ,ncol=sizeind)
rownames(appartenancepikp2) <- paste("k=",k)
colnames(appartenancepikp2) <- paste("ech",1:sizeind)
pikp2 <-  matrix(rep(NA,sizeind * N),nrow = N ,ncol=sizeind)
rownames(pikp2) <- paste("k=",k)
colnames(pikp2) <- paste("ech",1:sizeind)
  for (i in 1:sizeind){
    for(j in 1:N){
        appartenancepikp2[j,i] <- un_dedans(ind[i,],k[j])
        appartenancepikp2[appartenancepikp2==TRUE] <- 1
        appartenancepikp2[appartenancepikp2==FALSE] <- 0
        pikp2[j,i] <- round(appartenancepikp2[j,i] / n,2)
    }
  
  }
  head(appartenancepikp2,6)
  head(pikp2,6)
```

- Probabilité d'inclusion du second ordre

```{r}
appartenancepiklp2 <- matrix(rep(NA,sizek * sizeind),nrow = sizek ,ncol=sizeind)
rownames(appartenancepiklp2) <- paste(coupleij[,1],coupleij[,2],sep = ",")
colnames(appartenancepiklp2) <- paste("ech",1:sizeind)
piklp2<-  matrix(rep(NA,sizek * sizeind),nrow = sizek ,ncol=sizeind)
rownames(piklp2) <- paste(coupleij[,1],coupleij[,2],sep = ",")
colnames(piklp2) <- paste("ech",1:sizeind)
  for (i in 1:sizek){
    for(j in 1:sizeind){
        appartenancepiklp2[i,j] <- deux_dedans(ind[j,],coupleij[i,1],coupleij[i,2])
        appartenancepiklp2[appartenancepiklp2==TRUE] <- 1
        appartenancepiklp2[appartenancepiklp2==FALSE] <- 0
        piklp2[i,j] <- round(appartenancepiklp2[i,j] / n,2)
    }
   
    
  }
 head(appartenancepiklp2,6)
 head(piklp2,6)
```


**(b): La valeur de** $\boldsymbol{\bar{y_{u}}}$

```{r}
y <- c(98,102,154,133,190,175)
ybarmu <- mean(y)
ybarmu
```

**(c) Soit** $\boldsymbol{\bar{y}}$ **la moyenne des valeurs de l’échantillon. Pour chacun des plans trouvons**

**Plan1**

**i.** $\textbf{E}[\boldsymbol{\bar{y}}]:$

```{r}
# Moyenne de chaque echantillon du plan p1 
meanechtp1 <- rep(NA,sizeech)
for (i in 1:sizeech){
  meanechtp1[i] <- mean(y[x[i,]])
}
meanechtp1
# Moyenne de chaque echantillon du plan p1 
meanechtp2 <- rep(NA,sizeind)
for (i in 1:sizeind){
  meanechtp2[i] <- mean(y[ind[i,]])
}
meanechtp2
probp1 <- plan1[,4]
espybarp1 <- sum(probp1 * meanechtp1)
espybarp1
```

**ii.** $\textbf{V}[\boldsymbol{\bar{y}}]:$

Formule de la variance

$\text{V}[\bar{y}]=E[\bar{y^2}]-\text{E}[\bar{y}]^2$

```{r}
varybarp1 <- sum(meanechtp1^2*probp1) - espybarp1^2
varybarp1
```

**iii.**$\textbf{Biais}[\boldsymbol{\bar{y}}]:$

$\text{Biais}[\bar{y}]=\text{E}[\bar{y}] - \bar{y}_{\mu}$


```{r}
biaisybarp1 <- espybarp1 - ybarmu
biaisybarp1
```

**iiv.**$\textbf{EQM}[\boldsymbol{\bar{y}}]:$

Comme le biais est nul donc $\text{EQM}[\bar{y}]=\text{V}[\bar{y}]$

```{r}
eqmybarp1 <- varybarp1
```

**Plan2**

**i.** $\textbf{E}[\boldsymbol{\bar{y}}]:$

```{r}
probp2 <- plan2[,4]
espybarp2 <- sum(probp2 * meanechtp2)
espybarp2
```

**ii.** $\textbf{V}[\boldsymbol{\bar{y}}]:$

```{r}
varybarp2 <- sum(meanechtp2^2*probp2) - espybarp2^2
varybarp2
```

**iii.**$\textbf{Biais}[\boldsymbol{\bar{y}}]:$

```{r}
biaisybarp2 <- espybarp2 - ybarmu
biaisybarp2
```

**iiv.**$\textbf{EQM}[\boldsymbol{\bar{y}}]:$

```{r}
eqmybarp2 <- varybarp2 - biaisybarp2^2
eqmybarp2
```

**(d)Lequel des plans est le meilleur ? Pourquoi ?**

Le plan2 est le meilleur car il minimise le EQM

$2. \ $ Pour la population utilisée comme exemple en classe, formée de $8$ individus.

$$U=\{1, 2, 3, 4, 5, 6, 7, 8\}$$
**(a) Déterminons la probabilité de sélection $\boldsymbol{\pi_{i}}$ , pour chaque unité $\boldsymbol{i}$. **

Le nombre total des individus est de 8.
Donc la probabilité de selectionnée chaque individu est de $\frac{1}{8}$

$$\boxed{\pi_{i}=\frac{1}{8}}$$
**(b) Quelle est dans ce contexte la distribution de $\boldsymbol{\widehat{t}=8\bar{y}}$ ?**

```{r}
# extraction des echantillons
echtp3 <- plan[,1:4]
meanechtp3 <- apply(echtp3,1,mean)
tchap <- 8 * meanechtp3
hist(tchap,probability = TRUE)
shapiro.test(tchap)
```

Le test de normalité donne un p-value > 0.05 donc la distrubition de $\widehat{t}$ est une loi normale.
